{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waiting</th>\n",
       "      <th>sms_received</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>age</th>\n",
       "      <th>noshow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58565</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88457</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68295</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18648</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23798</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       waiting  sms_received  scholarship  diabetes  hypertension  age  noshow\n",
       "58565        0             0            0         0             0   64       0\n",
       "88457       25             1            0         0             0    3       0\n",
       "68295        9             0            0         0             0   10       1\n",
       "18648        7             0            0         0             1   58       0\n",
       "23798       28             1            0         0             1   34       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('med_appt_ml.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waiting</th>\n",
       "      <th>sms_received</th>\n",
       "      <th>scholarship</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>age</th>\n",
       "      <th>noshow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55021</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88213</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49781</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21960</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51588</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       waiting  sms_received  scholarship  diabetes  hypertension       age  \\\n",
       "55021        6             0            0         0             0  0.386667   \n",
       "88213       15             1            0         0             0  0.160000   \n",
       "49781        0             0            0         0             0  0.253333   \n",
       "21960       19             0            0         0             0  0.373333   \n",
       "51588        0             0            0         0             0  0.480000   \n",
       "\n",
       "       noshow  \n",
       "55021       0  \n",
       "88213       0  \n",
       "49781       0  \n",
       "21960       1  \n",
       "51588       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale data to make the range become 0-1\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "df['age'] = mm.fit_transform(df[['age']])\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "X = df.drop(columns='noshow')\n",
    "y = df['noshow']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalance handling\n",
    "sm = SMOTE()\n",
    "X_sm, y_sm = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building model\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_sm, y_sm)\n",
    "y_pred_LR = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "acc_LR = accuracy_score(y_test, y_pred_LR)\n",
    "pre_LR = precision_score(y_test, y_pred_LR)\n",
    "rec_LR = recall_score(y_test, y_pred_LR)\n",
    "f1_LR = f1_score(y_test, y_pred_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79     15427\n",
      "           1       0.32      0.56      0.41      3634\n",
      "\n",
      "    accuracy                           0.69     19061\n",
      "   macro avg       0.60      0.64      0.60     19061\n",
      "weighted avg       0.77      0.69      0.72     19061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 1</th>\n",
       "      <th>Pred 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act 1</th>\n",
       "      <td>2022</td>\n",
       "      <td>1612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act 0</th>\n",
       "      <td>4318</td>\n",
       "      <td>11109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pred 1  Pred 0\n",
       "Act 1    2022    1612\n",
       "Act 0    4318   11109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual-prediction table\n",
    "cm_LR = confusion_matrix(y_test, y_pred_LR, labels = [1,0])\n",
    "df_LR = pd.DataFrame(data = cm_LR , index = [\"Act 1\",\"Act 0\"], columns = [\"Pred 1\", \"Pred 0\"])\n",
    "df_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_tuning = LogisticRegression(random_state=42)\n",
    "para_LR = {'C': [1, 0.01, 0.015,  0.1, 0.5, 1.2, 2],\n",
    "           'penalty': ['l2', 'l1', 'elasticnet'], }\n",
    "LR_tuning = GridSearchCV(estimator=LR_tuning, param_grid=para_LR, cv=3, n_jobs=-1 , verbose=1, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "LR_tuning.fit(X_sm, y_sm)\n",
    "LR_tuned = LR_tuning.best_estimator_\n",
    "y_pred_LR_tuned = LR_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_tuning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "acc_LR_tuned = accuracy_score(y_test, y_pred_LR_tuned)\n",
    "pre_LR_tuned = precision_score(y_test, y_pred_LR_tuned)\n",
    "rec_LR_tuned = recall_score(y_test, y_pred_LR_tuned)\n",
    "f1_LR_tuned = f1_score(y_test, y_pred_LR_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.72      0.79     15427\n",
      "           1       0.32      0.56      0.41      3634\n",
      "\n",
      "    accuracy                           0.69     19061\n",
      "   macro avg       0.60      0.64      0.60     19061\n",
      "weighted avg       0.77      0.69      0.72     19061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred_LR_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 1</th>\n",
       "      <th>Pred 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act 1</th>\n",
       "      <td>2022</td>\n",
       "      <td>1612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act 0</th>\n",
       "      <td>4318</td>\n",
       "      <td>11109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pred 1  Pred 0\n",
       "Act 1    2022    1612\n",
       "Act 0    4318   11109"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual-prediction table\n",
    "cm_LR_tuned = confusion_matrix(y_test, y_pred_LR_tuned, labels = [1,0])\n",
    "df_LR_tuned = pd.DataFrame(data = cm_LR_tuned, index = [\"Act 1\",\"Act 0\"], columns = [\"Pred 1\", \"Pred 0\"])\n",
    "df_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(X_sm, y_sm)\n",
    "y_pred_KNN = KNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_KNN = accuracy_score(y_test, y_pred_KNN)\n",
    "pre_KNN = precision_score(y_test, y_pred_KNN)\n",
    "rec_KNN = recall_score(y_test, y_pred_KNN)\n",
    "f1_KNN = f1_score(y_test, y_pred_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82     15427\n",
      "           1       0.31      0.41      0.36      3634\n",
      "\n",
      "    accuracy                           0.71     19061\n",
      "   macro avg       0.58      0.60      0.59     19061\n",
      "weighted avg       0.75      0.71      0.73     19061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 1</th>\n",
       "      <th>Pred 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act 1</th>\n",
       "      <td>1505</td>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act 0</th>\n",
       "      <td>3331</td>\n",
       "      <td>12096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pred 1  Pred 0\n",
       "Act 1    1505    2129\n",
       "Act 0    3331   12096"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_KNN = confusion_matrix(y_test, y_pred_KNN, labels = [1,0])\n",
    "df_KNN = pd.DataFrame(data = cm_KNN, index = [\"Act 1\",\"Act 0\"], columns = [\"Pred 1\", \"Pred 0\"])\n",
    "df_KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_tuning = KNeighborsClassifier()\n",
    "param_KNN = {'n_neighbors': [5, 1, 10, 20],\n",
    "             'weights': ['uniform', 'distance'], \n",
    "             'leaf_size': [30, 10, 50, 70],\n",
    "             'p': [2,1]}\n",
    "KNN_tuning = GridSearchCV(estimator=KNN_tuning, param_grid=param_KNN, cv=3, n_jobs=-1 , verbose=1, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed:  7.6min finished\n"
     ]
    }
   ],
   "source": [
    "KNN_tuning.fit(X_sm, y_sm)\n",
    "KNN_tuned = KNN_tuning.best_estimator_\n",
    "y_pred_KNN_tuned = KNN_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 30, 'n_neighbors': 20, 'p': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_tuning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_KNN_tuned = accuracy_score(y_test, y_pred_KNN_tuned)\n",
    "rec_KNN_tuned = recall_score(y_test, y_pred_KNN_tuned)\n",
    "pre_KNN_tuned = precision_score(y_test, y_pred_KNN_tuned)\n",
    "f1_KNN_tuned = f1_score(y_test, y_pred_KNN_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78     15427\n",
      "           1       0.31      0.55      0.40      3634\n",
      "\n",
      "    accuracy                           0.68     19061\n",
      "   macro avg       0.59      0.63      0.59     19061\n",
      "weighted avg       0.76      0.68      0.71     19061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_KNN_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 1</th>\n",
       "      <th>Pred 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act 1</th>\n",
       "      <td>1990</td>\n",
       "      <td>1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act 0</th>\n",
       "      <td>4434</td>\n",
       "      <td>10993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pred 1  Pred 0\n",
       "Act 1    1990    1644\n",
       "Act 0    4434   10993"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_KNN_tuned = confusion_matrix(y_test, y_pred_KNN_tuned, labels = [1,0])\n",
    "df_KNN_tuned = pd.DataFrame(data = cm_KNN_tuned , index = [\"Act 1\",\"Act 0\"], columns = [\"Pred 1\", \"Pred 0\"])\n",
    "df_KNN_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(random_state=99)\n",
    "RFC.fit(X_sm, y_sm)\n",
    "y_pred_RFC = RFC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_RFC = accuracy_score(y_test, y_pred_RFC)\n",
    "pre_RFC = precision_score(y_test, y_pred_RFC)\n",
    "rec_RFC = recall_score(y_test, y_pred_RFC)\n",
    "f1_RFC = f1_score(y_test, y_pred_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80     15427\n",
      "           1       0.30      0.45      0.36      3634\n",
      "\n",
      "    accuracy                           0.69     19061\n",
      "   macro avg       0.58      0.60      0.58     19061\n",
      "weighted avg       0.75      0.69      0.71     19061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_RFC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 1</th>\n",
       "      <th>Pred 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act 1</th>\n",
       "      <td>1642</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act 0</th>\n",
       "      <td>3877</td>\n",
       "      <td>11550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pred 1  Pred 0\n",
       "Act 1    1642    1992\n",
       "Act 0    3877   11550"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_RFC = confusion_matrix(y_test, y_pred_RFC, labels = [1,0])\n",
    "df_RFC = pd.DataFrame(data = cm_RFC, index = [\"Act 1\",\"Act 0\"], columns = [\"Pred 1\", \"Pred 0\"])\n",
    "df_RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC_tuning = RandomForestClassifier(random_state=42)\n",
    "para_RFC = {'n_estimators': [100, 50, 80, 120, 200],\n",
    "           'max_depth': [None, 5, 10, 15],\n",
    "           'min_samples_split': [2, 5, 10, 20],\n",
    "           'min_samples_leaf': [1, 7, 15]}\n",
    "RFC_tuning = GridSearchCV(estimator=RFC_tuning, param_grid=para_RFC, cv=3, n_jobs=-1, verbose=1, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 21.1min finished\n"
     ]
    }
   ],
   "source": [
    "RFC_tuning.fit(X_sm, y_sm)\n",
    "RFC_tuned = RFC_tuning.best_estimator_\n",
    "y_pred_RFC_tuned = RFC_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_tuning.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_RFC_tuned = accuracy_score(y_test, y_pred_RFC_tuned)\n",
    "pre_RFC_tuned = precision_score(y_test, y_pred_RFC_tuned)\n",
    "rec_RFC_tuned = recall_score(y_test, y_pred_RFC_tuned)\n",
    "f1_RFC_tuned = f1_score(y_test, y_pred_RFC_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.47      0.62     15427\n",
      "           1       0.28      0.89      0.43      3634\n",
      "\n",
      "    accuracy                           0.55     19061\n",
      "   macro avg       0.61      0.68      0.53     19061\n",
      "weighted avg       0.82      0.55      0.59     19061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_RFC_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 1</th>\n",
       "      <th>Pred 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act 1</th>\n",
       "      <td>3227</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act 0</th>\n",
       "      <td>8237</td>\n",
       "      <td>7190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pred 1  Pred 0\n",
       "Act 1    3227     407\n",
       "Act 0    8237    7190"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_RFC_tuned = confusion_matrix(y_test, y_pred_RFC_tuned, labels = [1,0])\n",
    "df_RFC_tuned = pd.DataFrame(data = cm_RFC_tuned , index = [\"Act 1\",\"Act 0\"], columns = [\"Pred 1\", \"Pred 0\"])\n",
    "df_RFC_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation={'accuracy': [acc_LR, acc_LR_tuned, acc_KNN, acc_KNN_tuned, acc_RFC, acc_RFC_tuned],\n",
    "            'precision': [pre_LR, pre_LR_tuned, pre_KNN, pre_KNN_tuned, pre_RFC, pre_RFC_tuned],\n",
    "            'recall': [rec_LR, rec_LR_tuned, rec_KNN, rec_KNN_tuned, rec_RFC, rec_RFC_tuned],\n",
    "            'f1': [f1_LR, f1_LR_tuned, f1_KNN, f1_KNN_tuned, f1_RFC, f1_RFC_tuned]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.688894</td>\n",
       "      <td>0.318927</td>\n",
       "      <td>0.556412</td>\n",
       "      <td>0.405454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Reg. Tuned</th>\n",
       "      <td>0.688894</td>\n",
       "      <td>0.318927</td>\n",
       "      <td>0.556412</td>\n",
       "      <td>0.405454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.713551</td>\n",
       "      <td>0.311208</td>\n",
       "      <td>0.414144</td>\n",
       "      <td>0.355372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN Tuned</th>\n",
       "      <td>0.681129</td>\n",
       "      <td>0.309776</td>\n",
       "      <td>0.547606</td>\n",
       "      <td>0.395705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.692094</td>\n",
       "      <td>0.297518</td>\n",
       "      <td>0.451844</td>\n",
       "      <td>0.358789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Tuned</th>\n",
       "      <td>0.546509</td>\n",
       "      <td>0.281490</td>\n",
       "      <td>0.888002</td>\n",
       "      <td>0.427474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy  precision    recall        f1\n",
       "Logistic Regression  0.688894   0.318927  0.556412  0.405454\n",
       "Logistic Reg. Tuned  0.688894   0.318927  0.556412  0.405454\n",
       "KNN                  0.713551   0.311208  0.414144  0.355372\n",
       "KNN Tuned            0.681129   0.309776  0.547606  0.395705\n",
       "Random Forest        0.692094   0.297518  0.451844  0.358789\n",
       "Random Forest Tuned  0.546509   0.281490  0.888002  0.427474"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(evaluation, index=['Logistic Regression', 'Logistic Reg. Tuned', 'KNN', 'KNN Tuned', 'Random Forest', 'Random Forest Tuned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Medical check up cost may widely vary depending on what exams the patients take (up to 1300% difference for the same test)\n",
    "    - https://veja.abril.com.br/saude/precos-de-exames-laboratoriais-podem-variar-1300/\n",
    "    - The cost for routine check ranges from 100 - 600 Brazilian Real \n",
    "- Let us assume the medical check up is a complete check up (including cardial, lever, and urinal) for 340 Brazilian Real\n",
    "    - https://www.drconsulta.com/servicos/checkups\n",
    "    - If we missed 1 patient because of no-show, we may lose BRL340\n",
    "- Let us assume that the recommended solution we give:\n",
    "    - Reminder call and mailing cost BRL0.77 (https://olhardigital.com.br/noticia/ranking-revela-que-brasil-tem-a-ligacao-mais-cara/62835)\n",
    "    - Hiring new doctor cost BRL21,000 per month, which each doctor can handle 400 patients per month (BRL53 per patient)\n",
    "        - https://www.washingtonpost.com/news/to-your-health/wp/2014/05/22/how-many-patients-should-your-doctor-see-each-day/\n",
    "        - adding doctor is a way to shorten waiting time \n",
    "    - For these solutions, let us assume we spend BRL55 at most\n",
    "- The formula to count the effectiveness of machine learning is:\n",
    "    - without ML: (340)*((number of show up)+(number of no-show))/total patient\n",
    "    - with ML: \n",
    "        - ML cost: (340*FN)+(55*(TP+FP))\n",
    "        - ((340*(number of show up)-(ML cost))/total patient\n",
    "    - Revenue save = with ML - without ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USING RANDOM FOREST (HYPERPARAMETER TUNING)**\n",
    "- without ML:\n",
    "    - Total Revenue (19061 patients) = BRL4,009,620\n",
    "    - Single Revenue = BRL210/patient\n",
    "- with ML:\n",
    "    - ML cost (19061 patients) = BRL768,900\n",
    "    - Total Revenue (19061 patients) = BRL5,573,460\n",
    "    - Single Revenue = BRL292/patient\n",
    "- Revenue Increase after using ML model\n",
    "    - Total (for 19061 patient) = BRL1,563,840 = USD287,391\n",
    "    - Single = BRL82/patient = USD15/patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalized_model.sav']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(RFC_tuning, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.predict([[20, 0, 0, 0, 0, 25]])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49121596 0.50878404]]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.predict_proba([[20, 0, 0, 0, 0, 25]])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
